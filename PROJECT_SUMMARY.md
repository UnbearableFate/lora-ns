# PEFT Training Framework - å®Œæ•´æ€»ç»“

## é¡¹ç›®æ¦‚è¿°

å·²æˆåŠŸæ„å»ºä¸€å¥—å®Œæ•´çš„PEFTï¼ˆParameter-Efficient Fine-Tuningï¼‰è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒä½¿ç”¨HuggingFaceçš„transformersã€PEFTã€TRLå’ŒAccelerateåº“è¿›è¡Œå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒã€‚

## âœ… å·²å®Œæˆçš„åŠŸèƒ½

### 1. æ ¸å¿ƒè®­ç»ƒæ¨¡å—
- âœ… **train.py** - ä¸»è®­ç»ƒè„šæœ¬ï¼Œæ”¯æŒåˆ†ç±»å’Œå› æœè¯­è¨€æ¨¡å‹ä»»åŠ¡
- âœ… **inference.py** - æ¨ç†è„šæœ¬ï¼Œæ”¯æŒæ‰¹é‡æ¨ç†
- âœ… **merge_adapter.py** - LoRAæƒé‡åˆå¹¶è„šæœ¬
- âœ… **validate_config.py** - é…ç½®æ–‡ä»¶éªŒè¯å·¥å…·

### 2. å·¥å…·æ¨¡å— (utils/)
- âœ… **config_utils.py** - YAMLé…ç½®åŠ è½½å’ŒéªŒè¯
- âœ… **model_utils.py** - æ¨¡å‹åŠ è½½ä¸PEFTé›†æˆï¼ˆæ”¯æŒé‡åŒ–ï¼‰
- âœ… **dataset_loader.py** - æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†
- âœ… **metrics.py** - è¯„ä¼°æŒ‡æ ‡è®¡ç®—

### 3. é…ç½®æ–‡ä»¶ (configs/)
- âœ… **glue_mrpc.yaml** - GLUEæ–‡æœ¬åˆ†ç±»ä»»åŠ¡
- âœ… **metamath_qa.yaml** - MetaMathQAæ•°å­¦æ¨ç†ä»»åŠ¡
- âœ… **gsm8k.yaml** - GSM8Kæ•°å­¦é—®é¢˜æ±‚è§£
- âœ… **code_feedback.yaml** - ä»£ç ç”Ÿæˆä»»åŠ¡
- âœ… **template.yaml** - è‡ªå®šä¹‰ä»»åŠ¡æ¨¡æ¿
- âœ… **accelerate_config.yaml** - å¤šGPUè®­ç»ƒé…ç½®
- âœ… **deepspeed_config.json** - DeepSpeedé…ç½®

### 4. ç¤ºä¾‹è„šæœ¬ (examples/)
- âœ… **quick_start.py** - å¿«é€Ÿå…¥é—¨ç¤ºä¾‹
- âœ… **train_glue.sh** - GLUEè®­ç»ƒè„šæœ¬
- âœ… **train_metamath.sh** - MetaMathQAè®­ç»ƒè„šæœ¬
- âœ… **train_multi_gpu.sh** - å¤šGPUè®­ç»ƒè„šæœ¬
- âœ… **run_inference.sh** - æ¨ç†è¿è¡Œè„šæœ¬

### 5. æ–‡æ¡£
- âœ… **README.md** - å®Œæ•´ä½¿ç”¨æ–‡æ¡£
- âœ… **OVERVIEW.md** - é¡¹ç›®ç»“æ„æ¦‚è§ˆ
- âœ… **INSTALL.md** - å®‰è£…é…ç½®æŒ‡å—
- âœ… **requirements.txt** - Pythonä¾èµ–åˆ—è¡¨
- âœ… **.gitignore** - Gitå¿½ç•¥è§„åˆ™

## ğŸ¯ æ”¯æŒçš„ä»»åŠ¡ç±»å‹

### 1. æ–‡æœ¬åˆ†ç±» (Classification)
- **æ•°æ®é›†**: GLUE benchmark (MRPC, QQP, SST-2ç­‰)
- **æ¨¡å‹**: BERT, RoBERTa, ALBERT, DistilBERT
- **PEFTæ–¹æ³•**: LoRA (ç›®æ ‡å±‚: query, value)
- **ç‰¹ç‚¹**: 
  - æ”¯æŒå•å¥å’Œå¥å¯¹ä»»åŠ¡
  - è‡ªåŠ¨è®¡ç®—åˆ†ç±»æŒ‡æ ‡ï¼ˆaccuracy, F1, precision, recallï¼‰

### 2. å› æœè¯­è¨€æ¨¡å‹ (Causal LM)
æ”¯æŒä»¥ä¸‹ä»»åŠ¡ï¼š

#### a) æ•°å­¦æ¨ç† - MetaMathQA
- **æ•°æ®é›†**: 395Kæ•°å­¦é—®é¢˜ä¸è§£ç­”
- **æ¨¡å‹**: Llama-2, Mistral
- **LoRAé…ç½®**: r=16, alpha=32, å…¨å±‚å¾®è°ƒ
- **ç‰¹ç‚¹**: æ”¯æŒå¤æ‚æ•°å­¦æ¨ç†é“¾

#### b) å°å­¦æ•°å­¦ - GSM8K
- **æ•°æ®é›†**: 8.5Kå°å­¦æ•°å­¦åº”ç”¨é¢˜
- **æ¨¡å‹**: Mistral-7B
- **LoRAé…ç½®**: r=32, alpha=64ï¼ˆæ›´é«˜ç§©ä»¥è·å¾—æ›´å¥½æ€§èƒ½ï¼‰
- **ç‰¹ç‚¹**: é€æ­¥æ¨ç†è§£é¢˜

#### c) ä»£ç ç”Ÿæˆ - Code-Feedback
- **æ•°æ®é›†**: ä»£ç ç”Ÿæˆä¸åé¦ˆæ•°æ®
- **æ¨¡å‹**: CodeLlama, DeepSeek-Coder
- **LoRAé…ç½®**: r=16, alpha=32
- **ç‰¹ç‚¹**: æ”¯æŒä»£ç ç”Ÿæˆå’Œæ”¹è¿›

## ğŸ”§ æ ¸å¿ƒæŠ€æœ¯ç‰¹æ€§

### 1. PEFTæ–¹æ³•æ”¯æŒ
- **LoRA** (Low-Rank Adaptation) - ä¸»è¦æ–¹æ³•
  - å¯é…ç½®rank (r)ã€alphaã€dropout
  - æ”¯æŒé€‰æ‹©æ€§ç›®æ ‡æ¨¡å—
  - å†…å­˜é«˜æ•ˆ

- **Prefix Tuning** - æ·»åŠ å¯è®­ç»ƒå‰ç¼€
- **Prompt Tuning** - è½¯æç¤ºä¼˜åŒ–

### 2. é‡åŒ–æ”¯æŒ
- **4-bité‡åŒ–** (QLoRA)
  - ä½¿ç”¨NF4é‡åŒ–ç±»å‹
  - åŒé‡é‡åŒ–ä»¥èŠ‚çœæ›´å¤šå†…å­˜
  - é€‚åˆæ¶ˆè´¹çº§GPU

- **8-bité‡åŒ–**
  - å¹³è¡¡æ€§èƒ½å’Œå†…å­˜
  - ä½¿ç”¨bitsandbytesåº“

### 3. åˆ†å¸ƒå¼è®­ç»ƒ
- **Accelerateé›†æˆ**
  - å¤šGPUè®­ç»ƒ
  - æ··åˆç²¾åº¦è®­ç»ƒ (fp16/bf16)
  - è‡ªåŠ¨è®¾å¤‡æ˜ å°„

- **DeepSpeedæ”¯æŒ**
  - ZeRO Stage 2ä¼˜åŒ–
  - ä¼˜åŒ–å™¨å¸è½½åˆ°CPU
  - æ¢¯åº¦ç´¯ç§¯

### 4. SFT Traineré›†æˆ
- ä½¿ç”¨TRLåº“çš„SFTTrainer
- æ”¯æŒåºåˆ—æ‰“åŒ…
- è‡ªå®šä¹‰æ•°æ®æ ¼å¼åŒ–
- é«˜æ•ˆçš„å› æœLMè®­ç»ƒ

## ğŸ“Š é…ç½®ç³»ç»Ÿ

### YAMLé…ç½®ç»“æ„
```yaml
task_name: "ä»»åŠ¡åç§°"
task_type: "CAUSAL_LM" | "SEQ_CLS"

model:
  name_or_path: "æ¨¡å‹è·¯å¾„"
  trust_remote_code: true/false
  use_auth_token: true/false

peft:
  method: "lora" | "prefix-tuning" | "prompt-tuning"
  lora_r: 8-64
  lora_alpha: 16-128
  lora_dropout: 0.05-0.1
  target_modules: [...]
  task_type: "CAUSAL_LM" | "SEQ_CLS"

dataset:
  name: "æ•°æ®é›†åç§°"
  prompt_template: |
    æ¨¡æ¿å­—ç¬¦ä¸²

training:
  output_dir: "è¾“å‡ºç›®å½•"
  num_train_epochs: 1-10
  per_device_train_batch_size: 1-32
  gradient_accumulation_steps: 1-32
  learning_rate: 1e-5 - 5e-4
  # ... æ›´å¤šè®­ç»ƒå‚æ•°

sft:  # ä»…ç”¨äºcausal_lm
  max_seq_length: 512-4096
  packing: true/false
```

## ğŸš€ ä½¿ç”¨æµç¨‹

### 1. åŸºç¡€è®­ç»ƒ
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# éªŒè¯é…ç½®
python validate_config.py --all

# å¼€å§‹è®­ç»ƒ
python train.py --config configs/glue_mrpc.yaml
```

### 2. å¤šGPUè®­ç»ƒ
```bash
# é…ç½®Accelerate
accelerate config

# å¯åŠ¨è®­ç»ƒ
accelerate launch train.py --config configs/gsm8k.yaml
```

### 3. æ¨ç†
```bash
# å•æ–‡æœ¬æ¨ç†
python inference.py \
  --config configs/gsm8k.yaml \
  --model_path ./outputs/gsm8k \
  --input_text "é—®é¢˜æ–‡æœ¬"

# æ‰¹é‡æ¨ç†
python inference.py \
  --config configs/gsm8k.yaml \
  --model_path ./outputs/gsm8k \
  --input_file inputs.txt \
  --output_file results.json
```

### 4. æ¨¡å‹åˆå¹¶
```bash
python merge_adapter.py \
  --config configs/gsm8k.yaml \
  --adapter_path ./outputs/gsm8k \
  --output_path ./merged_model
```

## ğŸ’¡ æœ€ä½³å®è·µå»ºè®®

### å†…å­˜ä¼˜åŒ–
1. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (`gradient_checkpointing: true`)
2. ä½¿ç”¨é‡åŒ– (`optim: "paged_adamw_8bit"`)
3. å‡å°æ‰¹æ¬¡å¤§å°ï¼Œå¢åŠ æ¢¯åº¦ç´¯ç§¯
4. ä½¿ç”¨bf16è€Œéfp16ï¼ˆæ•°å€¼ç¨³å®šæ€§æ›´å¥½ï¼‰

### LoRAé…ç½®å»ºè®®
- **å°æ•°æ®é›†**: r=8, alpha=16
- **å¤§æ•°æ®é›†**: r=16-32, alpha=32-64
- **æœ€ä½³æ€§èƒ½**: ç›®æ ‡æ‰€æœ‰çº¿æ€§å±‚

### å­¦ä¹ ç‡å»ºè®®
- **åˆ†ç±»ä»»åŠ¡**: 3e-4 è‡³ 5e-4
- **å› æœLM**: 1e-4 è‡³ 2e-4
- **è°ƒåº¦å™¨**: cosine + warmup

## ğŸ“ é¡¹ç›®æ–‡ä»¶æ¸…å•

```
lora-ns/
â”œâ”€â”€ configs/                    # 6ä¸ªé…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ glue_mrpc.yaml
â”‚   â”œâ”€â”€ metamath_qa.yaml
â”‚   â”œâ”€â”€ gsm8k.yaml
â”‚   â”œâ”€â”€ code_feedback.yaml
â”‚   â”œâ”€â”€ template.yaml
â”‚   â”œâ”€â”€ accelerate_config.yaml
â”‚   â””â”€â”€ deepspeed_config.json
â”‚
â”œâ”€â”€ utils/                      # 5ä¸ªå·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_utils.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â”œâ”€â”€ dataset_loader.py
â”‚   â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ examples/                   # 5ä¸ªç¤ºä¾‹è„šæœ¬
â”‚   â”œâ”€â”€ quick_start.py
â”‚   â”œâ”€â”€ train_glue.sh
â”‚   â”œâ”€â”€ train_metamath.sh
â”‚   â”œâ”€â”€ train_multi_gpu.sh
â”‚   â””â”€â”€ run_inference.sh
â”‚
â”œâ”€â”€ train.py                   # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py               # æ¨ç†è„šæœ¬
â”œâ”€â”€ merge_adapter.py          # æ¨¡å‹åˆå¹¶è„šæœ¬
â”œâ”€â”€ validate_config.py        # é…ç½®éªŒè¯è„šæœ¬
â”‚
â”œâ”€â”€ requirements.txt          # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ README.md                 # ä½¿ç”¨æ–‡æ¡£
â”œâ”€â”€ OVERVIEW.md              # é¡¹ç›®æ¦‚è§ˆ
â”œâ”€â”€ INSTALL.md               # å®‰è£…æŒ‡å—
â””â”€â”€ .gitignore               # Gitå¿½ç•¥è§„åˆ™
```

## ğŸ”„ å¼€å‘çŠ¶æ€

âœ… **å·²å®Œæˆ**
- æ ¸å¿ƒè®­ç»ƒæµç¨‹å®ç°
- å¤šä»»åŠ¡æ”¯æŒï¼ˆåˆ†ç±»ã€å› æœLMï¼‰
- PEFTé›†æˆï¼ˆLoRAã€Prefix Tuningç­‰ï¼‰
- é‡åŒ–æ”¯æŒï¼ˆ4-bitã€8-bitï¼‰
- å¤šGPUè®­ç»ƒï¼ˆAccelerateã€DeepSpeedï¼‰
- æ•°æ®é›†åŠ è½½å™¨ï¼ˆæ”¯æŒ4ç§ä¸»è¦ä»»åŠ¡ï¼‰
- é…ç½®ç³»ç»Ÿï¼ˆYAMLç®¡ç†ï¼‰
- æ¨ç†å’Œæ¨¡å‹åˆå¹¶
- å®Œæ•´æ–‡æ¡£

ğŸ”® **å¯æ‰©å±•æ–¹å‘**
- æ·»åŠ æ›´å¤šPEFTæ–¹æ³•ï¼ˆIA3ã€AdaLoRAï¼‰
- æ”¯æŒæ›´å¤šæ•°æ®é›†
- é›†æˆWeights & Biases
- æ·»åŠ è¯„ä¼°è„šæœ¬
- æ”¯æŒRLHFè®­ç»ƒ
- æ·»åŠ æ¨¡å‹å‹ç¼©åŠŸèƒ½

## ğŸ“ å­¦ä¹ èµ„æº

### è®ºæ–‡
- LoRA: https://arxiv.org/abs/2106.09685
- QLoRA: https://arxiv.org/abs/2305.14314
- Prefix Tuning: https://arxiv.org/abs/2101.00190

### æ–‡æ¡£
- HuggingFace Transformers: https://huggingface.co/docs/transformers
- PEFT: https://huggingface.co/docs/peft
- TRL: https://huggingface.co/docs/trl
- Accelerate: https://huggingface.co/docs/accelerate

## ğŸ‰ æ€»ç»“

è¿™æ˜¯ä¸€ä¸ª**ç”Ÿäº§å°±ç»ª**çš„PEFTè®­ç»ƒæ¡†æ¶ï¼Œå…·æœ‰ï¼š
- ğŸ¯ **çµæ´»æ€§**: æ”¯æŒå¤šç§ä»»åŠ¡å’Œæ¨¡å‹
- âš¡ **é«˜æ•ˆæ€§**: é‡åŒ–å’Œåˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- ğŸ”§ **æ˜“ç”¨æ€§**: YAMLé…ç½®ç®¡ç†
- ğŸ“š **å®Œæ•´æ€§**: ä»è®­ç»ƒåˆ°æ¨ç†çš„å…¨æµç¨‹
- ğŸ“– **æ–‡æ¡£é½å…¨**: è¯¦ç»†çš„ä½¿ç”¨è¯´æ˜å’Œç¤ºä¾‹

å¯ä»¥ç›´æ¥ç”¨äºå­¦æœ¯ç ”ç©¶ã€å·¥ä¸šåº”ç”¨æˆ–æ•™å­¦æ¼”ç¤ºã€‚

## ğŸš€ ä¸‹ä¸€æ­¥

1. **å®‰è£…ä¾èµ–**: `pip install -r requirements.txt`
2. **éªŒè¯é…ç½®**: `python validate_config.py --all`
3. **å¿«é€Ÿæµ‹è¯•**: `python examples/quick_start.py`
4. **å¼€å§‹è®­ç»ƒ**: é€‰æ‹©åˆé€‚çš„é…ç½®æ–‡ä»¶å¼€å§‹ä½ çš„è®­ç»ƒï¼

ç¥è®­ç»ƒæ„‰å¿«ï¼ğŸŠ
